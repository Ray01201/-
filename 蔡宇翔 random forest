import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error

# 1) 讀取 Excel
df = pd.read_excel(r"C:\Users\user\Desktop\merged_file.xlsx")

# 2) 先把全部欄位做基本清理（去空白、把單位字串變成 NaN）
df = df.apply(lambda s: s.astype(str).str.strip())

unit_tokens = ["mm", "mm*mm", "mm*mm*mm", "A", "ps", "C", "pf"]
df = df.replace(unit_tokens, np.nan)

# 3) 目標欄位先轉成數字，轉不了就會是 NaN（用來把標頭列/單位列剔除）
df["Output 1"] = pd.to_numeric(df["Output 1"], errors="coerce")

# 只保留 Output 1 是有效數字的列（這一步會自動把標題列、單位列清掉）
df = df.dropna(subset=["Output 1"]).reset_index(drop=True)

# 4) 指定哪些欄位要做 one-hot（你原本的設定）
cat_cols = ["特徵值1", "特徵值2", "特徵值3", "特徵值4", "特徵值5",
            "特徵值7", "特徵值8", "特徵值15", "特徵值24"]

# 5) 其他欄位（非 cat_cols、非目標欄位）盡量轉成數字
#    轉不了的會變 NaN，後面再補值
for c in df.columns:
    if c not in cat_cols and c not in ["Output 1"]:
        df[c] = pd.to_numeric(df[c], errors="coerce")

# 6) one-hot
df_processed = pd.get_dummies(df, columns=cat_cols, dummy_na=True)

# 7) 定義 X / y
y = df_processed["Output 1"]

# 你的 X 設定：把不需要的欄位丟掉
X = df_processed.drop(
    ["Unnamed: 0", "Output 1", "Output 2", "Output 3", "Output 4", "Output 5", "特徵值10", "特徵值11"],
    axis=1,
    errors="ignore"
)

# 8) 把 X 裡剩下的 NaN 用「各欄位中位數」補起來（數字欄位）
X = X.apply(pd.to_numeric, errors="coerce")
X = X.fillna(X.median(numeric_only=True))

# 9) 切分資料
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# 10) 建模與訓練
model = RandomForestRegressor(
    n_estimators=1,
    max_depth=5,
    min_samples_split=10,
    min_samples_leaf=5,
    random_state=42,
    n_jobs=-1
)
model.fit(X_train, y_train)

# 11) 預測與評估
y_pred = model.predict(X_test)

y_train_pred = model.predict(X_train)
print(f"訓練集 R2: {r2_score(y_train, y_train_pred):.4f}")
print(f"測試集 R2: {r2_score(y_test, y_pred):.4f}")

mse = mean_squared_error(y_test, y_pred)
mape = mean_absolute_percentage_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"均方誤差 (MSE): {mse:.2f}")
print(f"MAPE (平均絕對百分比誤差): {mape * 100:.2f}%")
print(f"R-squared 分數: {r2:.2f}")

# 12) 特徵重要度（前 10）
importances = model.feature_importances_
feature_importance_df = (
    pd.DataFrame({"Feature": X.columns, "Importance": importances})
    .sort_values(by="Importance", ascending=False)
)
print(feature_importance_df.head(10))
